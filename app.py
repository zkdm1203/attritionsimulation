# app.py
import os
import joblib
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from dataclasses import dataclass
from typing import List, Tuple, Optional, Dict, Set

# ------------------------------
# Streamlit Page Config
# ------------------------------
st.set_page_config(
    page_title="Leadership Pipeline Simulation (Digital Twin‚ÄìInspired)",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ------------------------------
# Load Data & Model
# ------------------------------
@st.cache_data
def load_csv_same_dir(filename: str) -> pd.DataFrame:
    path = os.path.join(os.path.dirname(__file__), filename)
    if not os.path.exists(path):
        st.error(f"‚ùå File not found: {path}")
        st.stop()
    return pd.read_csv(path)

@st.cache_resource
def load_model_same_dir(filename: str):
    path = os.path.join(os.path.dirname(__file__), filename)
    if os.path.exists(path):
        try:
            return joblib.load(path)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Could not load model: {e}")
            return None
    return None

df_raw = load_csv_same_dir("Data.csv")
attrition_model = load_model_same_dir("attrition_model.pkl")

# ------------------------------
# Schema inference & features
# ------------------------------
def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out.columns = [c.strip().lower().replace(" ", "_") for c in out.columns]
    return out

df = normalize_cols(df_raw)

def first_existing(df, cols, default=None):
    for c in cols:
        if c in df.columns:
            return c
    return default

COL_ID      = first_existing(df, ["employee_number","employee_id","emp_id","id"], "emp_id")
if COL_ID not in df.columns:
    df[COL_ID] = np.arange(len(df)) + 1000

COL_ROLE    = first_existing(df, ["job_role","role","level","joblevel","job_level"], None)
if COL_ROLE is None:
    COL_ROLE = "role"
    rng = np.random.default_rng(42)
    df[COL_ROLE] = rng.choice(["IC","Manager","Senior"], p=[0.55,0.30,0.15], size=len(df))

COL_GENDER  = first_existing(df, ["gender","sex"], None)
if COL_GENDER is None:
    COL_GENDER = "gender"
    rng = np.random.default_rng(43)
    df[COL_GENDER] = rng.choice(["Male","Female","Nonbinary"], p=[0.6,0.38,0.02], size=len(df))

COL_RACE    = first_existing(df, ["race","ethnicity","race_ethnicity"], None)
if COL_RACE is None:
    COL_RACE = "race"
    rng = np.random.default_rng(44)
    df[COL_RACE] = rng.choice(["White","Asian","Black","Hispanic","Other"], p=[0.45,0.25,0.12,0.15,0.03], size=len(df))

COL_AGE     = first_existing(df, ["age"], None)
if COL_AGE is None:
    COL_AGE = "age"
    rng = np.random.default_rng(45)
    df[COL_AGE] = rng.integers(22, 65, size=len(df))

COL_TENURE  = first_existing(df, ["years_at_company","tenure_years","tenure"], None)
if COL_TENURE is None:
    COL_TENURE = "years_at_company"
    rng = np.random.default_rng(46)
    df[COL_TENURE] = np.round(np.clip((df[COL_AGE]-22)*rng.uniform(0.05,0.2,size=len(df)),0,40),1)

COL_PERF    = first_existing(df, ["performance_rating","performance","perf_score"], None)
if COL_PERF is None:
    COL_PERF = "performance_rating"
    rng = np.random.default_rng(47)
    df[COL_PERF] = rng.choice([1,2,3,4], p=[0.05,0.20,0.55,0.20], size=len(df))

COL_SKILLS  = first_existing(df, ["skills","skill_tags","top_skills"], None)
if COL_SKILLS is None:
    COL_SKILLS = "skills"
    rng = np.random.default_rng(48)
    possible = ["people_mgmt","project_mgmt","cloud","ml_ops","security","product","ai_governance","data","strategy"]
    df[COL_SKILLS] = [
        ",".join(rng.choice(possible, size=rng.integers(2,5), replace=False))
        for _ in range(len(df))
    ]

COL_ATTRITION = first_existing(df, ["attrition","left","churn"], None)
if COL_ATTRITION and df[COL_ATTRITION].dtype.kind not in "iu":
    tmp = df[COL_ATTRITION].astype(str).str.strip().str.lower().map(
        {"yes":1,"true":1,"1":1,"no":0,"false":0,"0":0}
    )
    if tmp.isna().any():
        tmp = tmp.fillna(0)
    df[COL_ATTRITION] = tmp.astype(int)

ROLE_MAP = {
    "ic": "IC",
    "individual_contributor": "IC",
    "junior": "IC",
    "associate": "IC",
    "manager": "Mid",
    "mid": "Mid",
    "mid-level": "Mid",
    "mid_level": "Mid",
    "lead": "Mid",
    "senior": "Senior",
    "director": "Senior",
    "vp": "Senior",
    "executive": "Senior"
}
df["role_level"] = df[COL_ROLE].astype(str).str.lower().map(lambda x: ROLE_MAP.get(x, "IC"))

# Skills & readiness helpers
def parse_skills(s) -> Set[str]:
    if pd.isna(s): return set()
    return set([t.strip().lower() for t in str(s).split(",") if t.strip()])

def jaccard(a:set, b:set):
    if not a and not b: return 0.0
    return len(a & b)/len(a | b)

TARGET_MID_SKILLS = {"people_mgmt","project_mgmt","product"}
TARGET_SENIOR_SKILLS = {"people_mgmt","product","ai_governance","strategy"}

skills_parsed = df[COL_SKILLS].apply(parse_skills)
df["skill_score_mid"] = skills_parsed.apply(lambda s: jaccard(s, set(TARGET_MID_SKILLS)))
df["skill_score_senior"] = skills_parsed.apply(lambda s: jaccard(s, set(TARGET_SENIOR_SKILLS)))

def minmax(x):
    return (x - x.min())/(x.max()-x.min()+1e-9) if len(x)>0 else x*0

perf_norm   = minmax(df[COL_PERF])
tenure_norm = minmax(df[COL_TENURE])
df["readiness_mid"]    = 0.5*perf_norm + 0.2*tenure_norm + 0.3*df["skill_score_mid"]
df["readiness_senior"] = 0.4*perf_norm + 0.2*tenure_norm + 0.4*df["skill_score_senior"]
READY_MID_TH    = 0.55
READY_SENIOR_TH = 0.60

# ------------------------------
# Attrition prob (model or heuristic)
# ------------------------------
def infer_attrition_prob(sub: pd.DataFrame) -> np.ndarray:
    # try the provided model with several feature sets
    if attrition_model is not None:
        candidate_feature_sets = [
            [COL_AGE, COL_TENURE, COL_PERF, COL_GENDER, COL_RACE, "role_level"],
            [COL_AGE, COL_TENURE, COL_PERF, "role_level"],
            [COL_TENURE, COL_PERF, "role_level"],
        ]
        for feats in candidate_feature_sets:
            try:
                X = sub[feats].copy()
                # one-hot minimal handling if model can't take strings
                for c in X.columns:
                    if X[c].dtype == 'O':
                        X = pd.get_dummies(X, columns=[c], drop_first=True)
                p = attrition_model.predict_proba(X)[:,1]
                return np.clip(p, 0.02, 0.60)
            except Exception:
                continue
        try:
            p = attrition_model.predict(sub[[COL_TENURE]].fillna(0))
            p = np.where(p>0.5, 0.35, 0.08)
            return np.clip(p, 0.02, 0.60)
        except Exception:
            pass

    # heuristic fallback
    base = np.where(sub["role_level"].eq("IC"), 0.16,
            np.where(sub["role_level"].eq("Mid"), 0.10, 0.07))
    adj_tenure = np.where(sub[COL_TENURE] < 1.0, +0.06, np.where(sub[COL_TENURE] < 3.0, +0.03, -0.01))
    adj_perf = np.interp(sub[COL_PERF], [df[COL_PERF].min(), df[COL_PERF].max()], [0.02, -0.02])
    p = base + adj_tenure + adj_perf
    return np.clip(p, 0.02, 0.60)

# ------------------------------
# Digital Twin‚ÄìInspired Simulation
# ------------------------------
@dataclass
class TwinConfig:
    years: int = 5
    annual_hiring_ic: int = 0
    annual_hiring_mid: int = 0
    retire_age: int = 62
    promote_bias_mid: float = 0.0
    promote_bias_senior: float = 0.0
    readiness_mid_th: float = READY_MID_TH
    readiness_senior_th: float = READY_SENIOR_TH
    diversity_boost: float = 0.0
    upskill_program: float = 0.0
    mid_demand_growth: float = 0.02
    senior_demand_growth: float = 0.02

@dataclass
class ScenarioResult:
    year: int
    headcount_ic: int
    headcount_mid: int
    headcount_senior: int
    mid_required: int
    mid_gap: int
    senior_required: int
    senior_gap: int
    mid_skill_coverage: float
    senior_skill_coverage: float
    avg_attrition_prob_mid: float
    avg_attrition_prob_senior: float
    diversity_mid_share: float
    diversity_senior_share: float

def is_urg(row) -> bool:
    is_urg_gender = str(row[COL_GENDER]).lower() in {"female","nonbinary"}
    is_urg_race   = str(row[COL_RACE]).lower() in {"black","hispanic","other"}
    return is_urg_gender or is_urg_race

def apply_upskill(d: pd.DataFrame, lift: float):
    if lift <= 0: 
        return d
    d = d.copy()
    d["skill_score_mid"]    = np.clip(d["skill_score_mid"] + lift, 0, 1)
    d["skill_score_senior"] = np.clip(d["skill_score_senior"] + lift, 0, 1)
    perf_norm   = minmax(d[COL_PERF])
    tenure_norm = minmax(d[COL_TENURE])
    d["readiness_mid"]    = 0.5*perf_norm + 0.2*tenure_norm + 0.3*d["skill_score_mid"]
    d["readiness_senior"] = 0.4*perf_norm + 0.2*tenure_norm + 0.4*d["skill_score_senior"]
    return d

def run_sim(initial: pd.DataFrame, config: TwinConfig) -> Tuple[pd.DataFrame, List[ScenarioResult]]:
    pop = initial.copy()
    results: List[ScenarioResult] = []
    base_mid_req    = (pop["role_level"]=="Mid").sum()
    base_senior_req = (pop["role_level"]=="Senior").sum()
    rng = np.random.default_rng(123)

    for year in range(1, config.years+1):
        pop = apply_upskill(pop, config.upskill_program)

        # Attrition
        p_leave = infer_attrition_prob(pop)
        leaving = rng.random(len(pop)) < p_leave
        pop = pop.loc[~leaving].copy()

        # Retirement
        retiring = pop[COL_AGE] >= config.retire_age
        pop = pop.loc[~retiring].copy()

        # Promotions
        def promote(source_role, target_role, readiness_col, threshold, bias, diversity_boost):
            pool = pop.loc[pop["role_level"].eq(source_role)].copy()
            if pool.empty: 
                return
            cand = pool.loc[pool[readiness_col] >= (threshold - 0.0)].copy()
            if cand.empty:
                return
            base = cand[readiness_col].values.copy()
            urg_mask = cand.apply(is_urg, axis=1).values
            bias_term = np.where(urg_mask, -bias, +bias)
            margin = np.clip((cand[readiness_col] - threshold).values, -0.10, 0.10)
            boost  = np.where(urg_mask & (margin < 0.02), diversity_boost, 0.0)
            score = base + bias_term + boost
            prob = (score - score.min())/(score.max()-score.min()+1e-9)
            take = rng.random(len(prob)) < prob
            promoted_ids = set(cand.loc[take, COL_ID].values.tolist())
            pop.loc[pop[COL_ID].isin(promoted_ids), "role_level"] = target_role

        promote("IC","Mid","readiness_mid", config.readiness_mid_th, config.promote_bias_mid, config.diversity_boost)
        promote("Mid","Senior","readiness_senior", config.readiness_senior_th, config.promote_bias_senior, config.diversity_boost)

        # Hiring backfill
        def hire(n, role):
            if n <= 0: return pd.DataFrame([])
            new = pd.DataFrame({
                COL_ID: np.arange(pop[COL_ID].max()+1, pop[COL_ID].max()+1+n),
                COL_AGE: rng.integers(23, 45, size=n) if role=="IC" else rng.integers(28, 55, size=n),
                COL_TENURE: 0.0,
                COL_PERF: rng.choice([1,2,3,4], size=n, p=[0.05,0.25,0.55,0.15]),
                COL_GENDER: rng.choice(["Male","Female","Nonbinary"], size=n, p=[0.55,0.43,0.02]),
                COL_RACE: rng.choice(["White","Asian","Black","Hispanic","Other"], size=n, p=[0.45,0.27,0.10,0.15,0.03]),
                COL_SKILLS: [
                    ",".join(rng.choice(["people_mgmt","project_mgmt","cloud","ml_ops","security","product","ai_governance","data","strategy"], 
                                        size=rng.integers(2,5), replace=False)) for _ in range(n)
                ],
                "role_level": role
            })
            sp = new[COL_SKILLS].apply(parse_skills)
            new["skill_score_mid"] = sp.apply(lambda s: jaccard(s, set(TARGET_MID_SKILLS)))
            new["skill_score_senior"] = sp.apply(lambda s: jaccard(s, set(TARGET_SENIOR_SKILLS)))
            perf_norm_n   = minmax(pd.concat([df[COL_PERF], new[COL_PERF]], ignore_index=True)).iloc[-n:]
            tenure_norm_n = 0.0
            new["readiness_mid"]    = 0.5*perf_norm_n + 0.2*tenure_norm_n + 0.3*new["skill_score_mid"]
            new["readiness_senior"] = 0.4*perf_norm_n + 0.2*tenure_norm_n + 0.4*new["skill_score_senior"]
            return new

        if config.annual_hiring_ic > 0:
            pop = pd.concat([pop, hire(config.annual_hiring_ic,"IC")], ignore_index=True)
        if config.annual_hiring_mid > 0:
            pop = pd.concat([pop, hire(config.annual_hiring_mid,"Mid")], ignore_index=True)

        # Demand growth
        mid_req    = int(round(base_mid_req * ((1+config.mid_demand_growth)**(year-1))))
        senior_req = int(round(base_senior_req * ((1+config.senior_demand_growth)**(year-1))))

        # Metrics
        hc_ic   = (pop["role_level"]=="IC").sum()
        hc_mid  = (pop["role_level"]=="Mid").sum()
        hc_sen  = (pop["role_level"]=="Senior").sum()

        mid_gap    = mid_req - hc_mid
        senior_gap = senior_req - hc_sen

        def coverage(role, col, th):
            part = pop.loc[pop["role_level"].eq(role), col]
            if len(part)==0: return 0.0
            return float((part >= th).mean())
        cov_mid = coverage("Mid","skill_score_mid",0.5)
        cov_sen = coverage("Senior","skill_score_senior",0.5)

        def avg_attr(role):
            sub = pop.loc[pop["role_level"].eq(role)]
            if len(sub)==0: return 0.0
            return float(infer_attrition_prob(sub).mean())
        attr_mid = avg_attr("Mid")
        attr_sen = avg_attr("Senior")

        def diversity_share(role):
            sub = pop.loc[pop["role_level"].eq(role)]
            if len(sub)==0: return 0.0
            urg = sub.apply(is_urg, axis=1).mean()
            return float(urg)
        div_mid = diversity_share("Mid")
        div_sen = diversity_share("Senior")

        results.append(ScenarioResult(
            year=year,
            headcount_ic=hc_ic,
            headcount_mid=hc_mid,
            headcount_senior=hc_sen,
            mid_required=mid_req,
            mid_gap=mid_gap,
            senior_required=senior_req,
            senior_gap=senior_gap,
            mid_skill_coverage=cov_mid,
            senior_skill_coverage=cov_sen,
            avg_attrition_prob_mid=attr_mid,
            avg_attrition_prob_senior=attr_sen,
            diversity_mid_share=div_mid,
            diversity_senior_share=div_sen
        ))

        # Age up & accrue tenure
        pop[COL_AGE]    = pop[COL_AGE] + 1
        pop[COL_TENURE] = pop[COL_TENURE] + 1

    return pop, results

def results_to_frame(results: List[ScenarioResult]) -> pd.DataFrame:
    return pd.DataFrame([r.__dict__ for r in results])

def static_successor_forecast(d: pd.DataFrame, years:int=5) -> pd.DataFrame:
    snap = d.copy()
    ready_mid = (snap["role_level"].eq("IC") & (snap["readiness_mid"] >= READY_MID_TH)).sum()
    ready_sen = (snap["role_level"].eq("Mid") & (snap["readiness_senior"] >= READY_SENIOR_TH)).sum()
    hc_mid_0  = (snap["role_level"]=="Mid").sum()
    hc_sen_0  = (snap["role_level"]=="Senior").sum()
    out = []
    for year in range(1, years+1):
        out.append({
            "year": year,
            "static_ready_mid": int(ready_mid),
            "static_ready_senior": int(ready_sen),
            "static_mid_supply": int(hc_mid_0 + ready_mid),
            "static_senior_supply": int(hc_sen_0 + ready_sen),
        })
    return pd.DataFrame(out)

# ------------------------------
# Sidebar controls for Simulation
# ------------------------------
st.sidebar.title("‚öôÔ∏è What-If Controls")
st.sidebar.caption(
    "Interactive workforce simulation that reveals dynamic pipeline vulnerabilities "
    "invisible to static succession planning."
)

years               = st.sidebar.slider("Years to simulate", 3, 10, 5)
annual_hire_ic_pct  = st.sidebar.slider("Annual IC External Hiring (%)", 0, 20, 10)
annual_hire_mid_pct = st.sidebar.slider("Annual Mid External Hiring (%)", 0, 10, 2)
retire_age          = st.sidebar.slider("Retirement Age", 55, 67, 62)

promote_bias_mid    = st.sidebar.slider(
    "Promotion Bias @ Mid (‚àí favors URG, + favors majority)",
    -0.1, 0.1, 0.0, 0.01,
    help="Negative values simulate correcting bias in favor of underrepresented groups; "
         "positive values simulate systems that advantage majority talent."
)
promote_bias_senior = st.sidebar.slider(
    "Promotion Bias @ Senior (‚àí favors URG, + favors majority)",
    -0.1, 0.1, 0.0, 0.01,
    help="Bias at senior levels is critical for long-term bench strength and board visibility."
)

diversity_boost     = st.sidebar.slider(
    "Diversity Boost Near Threshold",
    0.0, 0.15, 0.05, 0.01,
    help=(
        "Simulates targeted interventions for underrepresented groups‚Äîsuch as sponsorship programs, "
        "structured mentorship, and equitable performance calibration‚Äîthat research links to higher "
        "promotion rates."
    ),
)

upskill_program     = st.sidebar.slider(
    "Upskill Lift to Skills",
    0.0, 0.30, 0.15, 0.01,
    help="Represents sustained investment in development (leadership academies, stretch assignments, "
         "coaching) that increases readiness over multiple years."
)

mid_growth          = st.sidebar.slider("Mid Demand Growth (%)", 0, 10, 2)/100.0
senior_growth       = st.sidebar.slider("Senior Demand Growth (%)", 0, 10, 2)/100.0

base_ic  = (df["role_level"]=="IC").sum()
base_mid = (df["role_level"]=="Mid").sum()

config = TwinConfig(
    years=years,
    annual_hiring_ic  = int(round(base_ic  * (annual_hire_ic_pct/100.0))),
    annual_hiring_mid = int(round(base_mid * (annual_hire_mid_pct/100.0))),
    retire_age=retire_age,
    promote_bias_mid=promote_bias_mid,
    promote_bias_senior=promote_bias_senior,
    diversity_boost=diversity_boost,
    upskill_program=upskill_program,
    mid_demand_growth=mid_growth,
    senior_demand_growth=senior_growth
)

# ------------------------------
# Precompute scenarios
# ------------------------------
np.random.seed(42)
pop_baseline, res_baseline = run_sim(df, TwinConfig(
    years=years,
    annual_hiring_ic=int(round(base_ic*0.10)),
    annual_hiring_mid=int(round(base_mid*0.02)),
    retire_age=62,
    mid_demand_growth=0.02,
    senior_demand_growth=0.02
))
tbl_baseline = results_to_frame(res_baseline)

pop_scn, res_scn = run_sim(df, config)
tbl_scn = results_to_frame(res_scn)

static_tbl = static_successor_forecast(df, years=years)

# ------------------------------
# TABS
# ------------------------------
tabs = st.tabs([
    "üìä Data Overview",
    "ü§ñ Attrition Prediction",
    "üî≠ Leadership Gap Forecast",
    "üß† Skill Shortage Analysis",
    "üß™ What-If Simulation (Digital Twin‚ÄìInspired)",
    "üö® Retention Risk Forecast",
    "üåç Diversity & DEI",
    "‚öñÔ∏è Static vs Simulation",
    "üéØ Research & Methodology",
])

# ===== Tab 1: Data Overview =====
with tabs[0]:
    st.subheader("Dataset Preview & Summary")
    st.markdown(
        "This prototype uses a blend of sample HR data and synthetic augmentation to mimic a tech workforce. "
        "The goal is not to perfectly represent any one company, but to **demonstrate how simulation can make "
        "succession planning more dynamic and transparent**."
    )
    st.dataframe(df.head(), use_container_width=True)
    st.write(df.describe(include='all'))

    st.subheader("Role Level Distribution")
    fig, ax = plt.subplots()
    df["role_level"].value_counts().reindex(["IC","Mid","Senior"]).plot(kind="bar", ax=ax)
    ax.set_ylabel("Count")
    st.pyplot(fig)

    st.subheader("Performance Rating Distribution")
    fig, ax = plt.subplots()
    df[COL_PERF].plot(kind="hist", bins=12, ax=ax)
    ax.set_xlabel("Performance"); ax.set_ylabel("Count")
    st.pyplot(fig)

# ===== Tab 2: Attrition Prediction (with input form) =====
with tabs[1]:
    st.subheader("Predict Attrition Risk + Promotion Readiness")

    col1, col2, col3 = st.columns(3)
    with col1:
        in_age = st.number_input("Age", min_value=18, max_value=75, value=30, step=1)
        in_tenure = st.number_input("Years at Company", min_value=0.0, max_value=40.0, value=2.0, step=0.1)
        in_perf = st.slider("Performance Rating (1-4)", 1, 4, 3)
    with col2:
        in_role = st.selectbox("Role Level", ["IC","Mid","Senior"])
        in_gender = st.selectbox("Gender", ["Male","Female","Nonbinary"])
        in_race = st.selectbox("Race/Ethnicity", ["White","Asian","Black","Hispanic","Other"])
    with col3:
        in_skills = st.text_input("Skills (comma-separated)", "people_mgmt, project_mgmt, product")

    if st.button("Predict"):
        # Build a one-row DF with the same schema
        pred_df = pd.DataFrame([{
            COL_ID: 999999,
            COL_AGE: in_age,
            COL_TENURE: in_tenure,
            COL_PERF: in_perf,
            COL_GENDER: in_gender,
            COL_RACE: in_race,
            COL_SKILLS: in_skills,
            "role_level": in_role
        }])

        # compute skill & readiness for the candidate
        sset = parse_skills(in_skills)
        pred_df["skill_score_mid"] = jaccard(sset, TARGET_MID_SKILLS)
        pred_df["skill_score_senior"] = jaccard(sset, TARGET_SENIOR_SKILLS)
        # normalize perf/tenure relative to population (robust)
        def rminmax(val, series):
            mn, mx = series.min(), series.max()
            return (val - mn) / (mx - mn + 1e-9)
        pnorm = rminmax(in_perf, df[COL_PERF])
        tnorm = rminmax(in_tenure, df[COL_TENURE])
        pred_df["readiness_mid"] = 0.5*pnorm + 0.2*tnorm + 0.3*pred_df["skill_score_mid"]
        pred_df["readiness_senior"] = 0.4*pnorm + 0.2*tnorm + 0.4*pred_df["skill_score_senior"]

        # Attrition prob from model/heuristic
        try:
            ap = float(infer_attrition_prob(pred_df)[0])
        except Exception as e:
            ap = np.nan
            st.warning(f"Prediction failed; details: {e}")

        st.markdown("#### Results")
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("Predicted Attrition Risk", f"{ap*100:.1f}%" if not np.isnan(ap) else "N/A")
        with c2:
            st.metric("Readiness (IC‚ÜíMid)", f"{float(pred_df['readiness_mid'])*100:.1f}%")
            st.caption(f"Ready-now threshold: {READY_MID_TH*100:.0f}%")
        with c3:
            st.metric("Readiness (Mid‚ÜíSenior)", f"{float(pred_df['readiness_senior'])*100:.1f}%")
            st.caption(f"Ready-now threshold: {READY_SENIOR_TH*100:.0f}%")

        # Simple rule-based recommendation
        recs = []
        if in_role == "IC" and float(pred_df["readiness_mid"]) >= READY_MID_TH:
            recs.append("‚úÖ Promote to Mid: readiness meets threshold.")
        elif in_role == "IC":
            recs.append("üìà Upskill for Mid: strengthen people_mgmt / project_mgmt / product.")
        if in_role == "Mid" and float(pred_df["readiness_senior"]) >= READY_SENIOR_TH:
            recs.append("‚úÖ Consider promotion to Senior: readiness meets threshold.")
        elif in_role == "Mid":
            recs.append("üìà Upskill for Senior: focus on product / strategy / AI governance.")
        if not np.isnan(ap):
            if ap >= 0.25:
                recs.append("‚ö†Ô∏è Retention Risk: consider tailored retention plan.")
            else:
                recs.append("üôÇ Retention risk looks manageable.")
        st.write("\n".join(recs))

# ===== Tab 3: Leadership Gap Forecast =====
with tabs[2]:
    st.subheader("Mid-Level Leadership Gap Over Time")
    st.caption(
        "Here we compare how many Mid-level leaders you **need** (demand) versus how many you actually "
        "have after accounting for attrition, retirements, promotions, and hiring."
    )
    c = st.columns(2)
    with c[0]:
        st.write("**Baseline (default settings)**")
        fig, ax = plt.subplots()
        ax.plot(tbl_baseline["year"], tbl_baseline["mid_gap"], marker="o")
        ax.set_xlabel("Year"); ax.set_ylabel("Gap (Required ‚àí Headcount)"); ax.grid(True)
        st.pyplot(fig)
    with c[1]:
        st.write("**Your Scenario (sidebar controls)**")
        fig, ax = plt.subplots()
        ax.plot(tbl_scn["year"], tbl_scn["mid_gap"], marker="o")
        ax.set_xlabel("Year"); ax.set_ylabel("Gap (Required ‚àí Headcount)"); ax.grid(True)
        st.pyplot(fig)

# ===== Tab 4: Skill Shortage Analysis =====
with tabs[3]:
    st.subheader("Mid & Senior Skill Coverage")
    st.caption(
        "Skill coverage approximates whether you have enough people with the capabilities you care about "
        "(Mid: people & project management; Senior: product, strategy, AI governance)."
    )
    c = st.columns(2)
    with c[0]:
        st.write("**Mid Skill Coverage**")
        fig, ax = plt.subplots()
        ax.plot(tbl_baseline["year"], tbl_baseline["mid_skill_coverage"], marker="o", label="Baseline")
        ax.plot(tbl_scn["year"], tbl_scn["mid_skill_coverage"], marker="o", label="Scenario")
        ax.set_ylim(0,1); ax.set_xlabel("Year"); ax.set_ylabel("Share ‚â• threshold"); ax.grid(True); ax.legend()
        st.pyplot(fig)
    with c[1]:
        st.write("**Senior Skill Coverage**")
        fig, ax = plt.subplots()
        ax.plot(tbl_baseline["year"], tbl_baseline["senior_skill_coverage"], marker="o", label="Baseline")
        ax.plot(tbl_scn["year"], tbl_scn["senior_skill_coverage"], marker="o", label="Scenario")
        ax.set_ylim(0,1); ax.set_xlabel("Year"); ax.set_ylabel("Share ‚â• threshold"); ax.grid(True); ax.legend()
        st.pyplot(fig)

# ===== Tab 5: What-If Simulation (Digital Twin‚ÄìInspired) =====
with tabs[4]:
    st.subheader("What-If Simulation (Digital Twin‚ÄìInspired)")
    st.markdown(
        "This page treats your workforce as a **simulated system**: each year, people leave, retire, get promoted, "
        "and new hires join. While it is inspired by digital twin principles, it is **not yet a full digital twin** "
        "because it does not stream live HRIS data."
    )
    c = st.columns(2)
    with c[0]:
        st.write("**Mid Gap (Your Scenario)**")
        fig, ax = plt.subplots()
        ax.plot(tbl_scn["year"], tbl_scn["mid_gap"], marker="o")
        ax.set_xlabel("Year"); ax.set_ylabel("Gap"); ax.grid(True)
        st.pyplot(fig)
    with c[1]:
        st.write("**Senior Gap (Your Scenario)**")
        fig, ax = plt.subplots()
        ax.plot(tbl_scn["year"], tbl_scn["senior_gap"], marker="o")
        ax.set_xlabel("Year"); ax.set_ylabel("Gap"); ax.grid(True)
        st.pyplot(fig)

    st.caption(
        "Use the sidebar to test earlier retirements, different hiring strategies, stronger upskilling, or "
        "DEI interventions ‚Äî and see how your future bench strength changes."
    )

# ===== Tab 6: Retention Risk Forecast =====
with tabs[5]:
    st.subheader("Mid-Level Attrition Probability Over Time")
    st.caption(
        "High mid-level attrition is one of the main reasons organizations experience sudden leadership gaps. "
        "This view shows how average Mid-level attrition risk evolves under different scenarios."
    )
    fig, ax = plt.subplots()
    ax.plot(tbl_baseline["year"], tbl_baseline["avg_attrition_prob_mid"], marker="o", label="Baseline")
    ax.plot(tbl_scn["year"], tbl_scn["avg_attrition_prob_mid"], marker="o", label="Scenario")
    ax.set_ylim(0,0.6); ax.set_xlabel("Year"); ax.set_ylabel("Probability")
    ax.grid(True); ax.legend()
    st.pyplot(fig)

# ===== Tab 7: Diversity & DEI =====
with tabs[6]:
    st.subheader("Diversity in Leadership")
    st.markdown(
        """
This view tracks **underrepresented groups (URG)** in leadership ‚Äî defined here as women, non-binary talent,
and employees who identify as Black, Hispanic, or Other.

The `Diversity Boost Near Threshold` control in the sidebar simulates **structural interventions** highlighted in
the DEI literature, such as more equitable performance calibration, access to sponsorship, and transparent promotion
criteria. These interventions increase the likelihood that URG talent just below the readiness threshold actually moves
into leadership roles instead of leaking out of the pipeline.
        """
    )
    c = st.columns(2)
    with c[0]:
        st.write("**Mid-Level Diversity Share**")
        fig, ax = plt.subplots()
        ax.plot(tbl_baseline["year"], tbl_baseline["diversity_mid_share"], marker="o", label="Baseline")
        ax.plot(tbl_scn["year"], tbl_scn["diversity_mid_share"], marker="o", label="Scenario")
        ax.set_ylim(0,1); ax.set_xlabel("Year"); ax.set_ylabel("URG Share")
        ax.grid(True); ax.legend()
        st.pyplot(fig)
    with c[1]:
        st.write("**Senior-Level Diversity Share**")
        fig, ax = plt.subplots()
        ax.plot(tbl_baseline["year"], tbl_baseline["diversity_senior_share"], marker="o", label="Baseline")
        ax.plot(tbl_scn["year"], tbl_scn["diversity_senior_share"], marker="o", label="Scenario")
        ax.set_ylim(0,1); ax.set_xlabel("Year"); ax.set_ylabel("URG Share")
        ax.grid(True); ax.legend()
        st.pyplot(fig)

# ===== Tab 8: Static vs Simulation =====
with tabs[7]:
    st.subheader("Static Succession Planning (No Dynamics)")
    st.markdown(
        "Static planning assumes the current list of 'ready now' successors is stable. "
        "It does **not** account for future attrition, retirements, or promotion timing."
    )
    st.dataframe(static_tbl, use_container_width=True)

    st.subheader("Dynamic Simulation (Digital Twin‚ÄìInspired)")
    st.markdown(
        "The simulation, by contrast, updates the pipeline year by year as people leave, move up, or enter. "
        "This is closer to how the real workforce behaves ‚Äî and highlights why static lists often **overestimate** "
        "bench strength."
    )
    st.dataframe(tbl_scn, use_container_width=True)

    st.caption(
        "Example scenario: A company may list five 'ready now' successors for a senior role. Once you factor in "
        "Mid-level attrition and promotion velocity over several years, the simulation can reveal that only two of "
        "them are still around and ready when the role actually opens ‚Äî a 60% shortfall that static planning hides."
    )

# ===== Tab 9: Research & Methodology =====
with tabs[8]:
    st.subheader("Problem & Research Question")
    st.markdown(
        """
Organizations routinely invest in succession planning, yet many rate its effectiveness around **5.5/10**.
One reason: most tools are **static** ‚Äî they cannot show how attrition, retirements, promotions, and hiring
interact over time to create surprise leadership gaps.

**Research question:**  
Can an interactive workforce simulation ‚Äî inspired by digital twin principles ‚Äî reveal mid-level leadership
gaps and pipeline vulnerabilities that static succession planning misses?
        """
    )

    st.subheader("What This Tool Is (and Isn‚Äôt)")
    st.markdown(
        """
- ‚úÖ **Is:** An interactive workforce **simulation** that models attrition, retirements, promotions, hiring,
  skills, and DEI levers over a multi-year horizon.  
- ‚úÖ **Is:** A way to make abstract concepts like ‚Äúbench strength‚Äù and ‚Äúpipeline leakage‚Äù visible and measurable.  
- ‚ö†Ô∏è **Is not yet:** A fully-fledged **digital twin**, because it does not continuously ingest live HRIS data or
  update in real time.  
- üéØ **Design intent:** Use simulation modeling to demonstrate the value of **dynamic workforce forecasting** for
  leadership and succession planning.
        """
    )

    st.subheader("Methodology & Key Assumptions (Summary)")
    st.markdown(
        f"""
- **Data foundation:** Sample HR-like dataset with synthetic augmentation to approximate a tech workforce.  
- **Role structure:** Workforce split into three levels ‚Äî IC, Mid, Senior ‚Äî via the `{COL_ROLE}` / `role_level`
  mapping.  
- **Attrition modeling:** Uses a trained attrition model when available; otherwise a calibrated heuristic that
  varies by role, tenure, and performance.  
- **Readiness rules:**  
  - IC ‚Üí Mid readiness combines performance, tenure, and **Mid skill score** (people & project management, product).  
  - Mid ‚Üí Senior readiness combines performance, tenure, and **Senior skill score** (product, strategy, AI governance).  
- **Demand growth:** Mid and Senior role demand grows by configurable annual percentages to mirror business growth.  
- **Retirement:** Employees at or above a configurable retirement age exit the system in each simulated year.  
- **DEI lens:** URG talent is defined as women, non-binary employees, and employees who identify as Black, Hispanic,
  or Other. The diversity boost and bias sliders approximate structural barriers vs targeted interventions.  
- **Time step:** The model runs in **annual** steps; within each year it applies attrition ‚Üí retirement ‚Üí promotions
  ‚Üí hiring ‚Üí aging.
        """
    )

    st.subheader("Validation & Credibility (Prototype Level)")
    st.markdown(
        """
This is a **proof-of-concept**, not a production HR product, so validation is framed accordingly:

1. **Internal consistency checks**  
   - Extreme ‚Äúwhat-if‚Äù settings behave as expected (e.g., zero hiring + early retirements quickly produce large gaps).  
   - Increasing upskilling and reducing bias improves readiness and diversity over time, not just in a single year.

2. **Scenario-based evidence vs static planning**  
   - Static succession counts remain flat over time, even as attrition and retirements should logically reduce the pool.  
   - The simulation shows how, under realistic attrition rates, the supply of truly available successors can fall well
     below what static lists suggest.

3. **Path to real-world validation**  
   - In a real deployment, this approach would be validated against **historical workforce data** and/or structured
     feedback from HR practitioners (e.g., ‚ÄúDoes this surface pipeline risks that your current tools miss?‚Äù).
        """
    )

    def quick_findings(tbl_base: pd.DataFrame, tbl_scn: pd.DataFrame) -> Dict[str,str]:
        out = {}
        gap_base = int(tbl_base["mid_gap"].sum())
        gap_scn  = int(tbl_scn["mid_gap"].sum())
        out["gap_compare"] = f"Cumulative Mid gaps ‚Äî Baseline vs Scenario: {gap_base} vs {gap_scn} (lower is better)."
        cov_base = tbl_base["mid_skill_coverage"].mean()
        cov_scn  = tbl_scn["mid_skill_coverage"].mean()
        out["skill"] = f"Avg Mid skill coverage ‚Äî Baseline vs Scenario: {cov_base:.2f} vs {cov_scn:.2f}."
        div_base = tbl_base["diversity_mid_share"].mean()
        div_scn  = tbl_scn["diversity_mid_share"].mean()
        out["div"]  = f"Avg Mid diversity share ‚Äî Baseline vs Scenario: {div_base:.2f} vs {div_scn:.2f}."
        r_base = tbl_base["avg_attrition_prob_mid"].mean()
        r_scn  = tbl_scn["avg_attrition_prob_mid"].mean()
        out["risk"] = f"Avg Mid attrition risk ‚Äî Baseline vs Scenario: {r_base:.2f} vs {r_scn:.2f}."
        return out

    st.subheader("Quantitative Comparison: Baseline vs Your Scenario")
    kf = quick_findings(tbl_baseline, tbl_scn)
    st.markdown(
        f"""
- **Leadership Gaps:** {kf['gap_compare']}  
- **Skills:** {kf['skill']}  
- **DEI:** {kf['div']}  
- **Retention Risk:** {kf['risk']}  
"""
    )

    st.subheader("Limitations & Future Work")
    st.markdown(
        """
- **Synthetic / sample data:** Results are illustrative, not prescriptions for any specific company.  
- **No role obsolescence modeling (yet):** Although the literature highlights automation risk (e.g., WEF 2020), this
  version does not reduce demand for roles that are likely to be automated.  
  - Future iteration: Add a **‚ÄúRole Automation Risk‚Äù** parameter per role family and integrate external sources such
    as **O*NET automation probability scores** to gradually reduce demand for high-risk roles.  
- **No live HRIS integration:** A true digital twin would pull real data continuously from HR systems and learn from
  actual outcomes.  
- **Calibration required:** Each organization would need to calibrate attrition probabilities, readiness thresholds,
  and promotion rules to its own culture and labor market reality.
        """
    )

    st.success(
        "Conclusion: This interactive workforce simulation surfaces mid-level leadership gaps, skill bottlenecks, "
        "and diversity trade-offs that static succession lists cannot show, by modeling attrition, retirements, "
        "promotions, external hiring, and upskilling over time. It is **not** yet a full digital twin, but it is "
        "**digital-twin inspired** and demonstrates how dynamic workforce forecasting can make succession planning "
        "more honest and actionable."
    )
